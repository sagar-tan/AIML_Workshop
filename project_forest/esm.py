# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k-6t1weo3abZ0UtZUVV7PfKfmUifidvt
"""

!pip install fair-esm biopython

import torch
import esm
import numpy as np
from Bio import SeqIO

model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()
model = model.eval().cuda() if torch.cuda.is_available() else model.eval()
batch_converter = alphabet.get_batch_converter()

sequence="""MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAED
LQVGQVELGGGPGAGSLQPLALEGSLQKRGIVEQCCTSICSLYQLENYCN"""
data = [("protein1", sequence)]
batch_labels, batch_strs, batch_tokens = batch_converter(data)
if torch.cuda.is_available():
    batch_tokens = batch_tokens.cuda()

with torch.no_grad():
    results = model(batch_tokens, repr_layers=[6])
token_representations = results["representations"][6]

protein_embedding = token_representations.mean(1).cpu().numpy()
protein_embedding.shape