# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MKXhkpUIoI3hvjvVmPU7CQt-gsk7mvN5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve

np.random.seed(42)

n_samples = 500

data = pd.DataFrame({
    "molecular_weight": np.random.normal(400, 50, n_samples),
    "logP": np.random.normal(3, 1, n_samples),
    "hbond_donors": np.random.randint(0, 6, n_samples),
    "hbond_acceptors": np.random.randint(2, 10, n_samples),
    "tpsa": np.random.normal(80, 20, n_samples),
    "rotatable_bonds": np.random.randint(1, 12, n_samples),
    "pocket_volume": np.random.normal(500, 100, n_samples),
    "pocket_hydrophobicity": np.random.normal(0.5, 0.1, n_samples),
})

# Create label with some logic (hidden biological pattern)
data["label"] = (
    (data["logP"] > 2.5) &
    (data["hbond_donors"] <= 3) &
    (data["pocket_volume"] > 450)
).astype(int)

data.head()

print("Dataset Shape:", data.shape)
print("\nClass Distribution:")
print(data["label"].value_counts())

sns.countplot(x="label", data=data)
plt.title("Binder vs Non-Binder Distribution")
plt.show()

X = data.drop("label", axis=1)
y = data["label"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

log_model = LogisticRegression()
log_model.fit(X_train_scaled, y_train)

y_pred_log = log_model.predict(X_test_scaled)

print("Accuracy:", accuracy_score(y_test, y_pred_log))
print("\nClassification Report:\n", classification_report(y_test, y_pred_log))

cm = confusion_matrix(y_test, y_pred_log)
sns.heatmap(cm, annot=True, fmt="d")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

y_prob_rf = rf_model.predict_proba(X_test)[:,1]

fpr, tpr, thresholds = roc_curve(y_test, y_prob_rf)
auc_score = roc_auc_score(y_test, y_prob_rf)

plt.plot(fpr, tpr)
plt.plot([0,1],[0,1],'--')
plt.title(f"ROC Curve (AUC = {auc_score:.2f})")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

importances = rf_model.feature_importances_
feature_names = X.columns

feat_imp = pd.Series(importances, index=feature_names)
feat_imp.sort_values().plot(kind='barh')
plt.title("Feature Importance - Random Forest")
plt.show()

